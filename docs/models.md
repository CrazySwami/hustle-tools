anthropic logo
Anthropic

:

Claude 4 Sonnet

Claude Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities, excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model balances performance and efficiency for internal and external use cases, with enhanced steerability for greater control over implementations. While not matching Opus 4 in most domains, it delivers an optimal mix of capability and practicality.

Context 200K

Input Tokens $3.00/M

Output Tokens $15.00/M

Cache Read Tokens $0.30/M

Cache Write Tokens $3.75/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

openai logo
OpenAI

:

GPT-5

GPT-5 is OpenAI's flagship language model that excels at complex reasoning, broad real-world knowledge, code-intensive, and multi-step agentic tasks.

Context 400K

Input Tokens $1.25/M

Output Tokens $10.00/M

Cache Read Tokens $0.13/M

openai logo
Available on 1 provider

openai logo
OpenAI

:

GPT-5 mini

GPT-5 mini is a cost optimized model that excels at reasoning/chat tasks. It offers an optimal balance between speed, cost, and capability.

Context 400K

Input Tokens $0.25/M

Output Tokens $2.00/M

Cache Read Tokens $0.03/M

openai logo
Available on 1 provider

openai logo
OpenAI

:

GPT-5 nano

GPT-5 nano is a high throughput model that excels at simple instruction or classification tasks.

Context 400K

Input Tokens $0.05/M

Output Tokens $0.40/M

Cache Read Tokens $0.01/M

openai logo
Available on 1 provider

openai logo
OpenAI

:

gpt-oss-120b

Extremely capable general-purpose LLM with strong, controllable reasoning capabilities

Context 131K

Input Tokens $0.10/M

Output Tokens $0.50/M

baseten logo
cerebras logo
fireworks logo
+2
Available on 5 providers

google logo
Google

:

Gemini 2.5 Flash

Gemini 2.5 Flash is a thinking model that offers great, well-rounded capabilities. It is designed to offer a balance between price and performance with multimodal support and a 1M token context window.

Context 1M

Input Tokens $0.30/M

Output Tokens $2.50/M

vertex logo
Available on 1 provider

anthropic logo
Anthropic

:

Claude 3.7 Sonnet

Claude 3.7 Sonnet is the first hybrid reasoning model and Anthropic's most intelligent model to date. It delivers state-of-the-art performance for coding, content generation, data analysis, and planning tasks, building upon its predecessor Claude 3.5 Sonnet's capabilities in software engineering and computer use.

Context 200K

Input Tokens $3.00/M

Output Tokens $15.00/M

Cache Read Tokens $0.30/M

Cache Write Tokens $3.75/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

google logo
Google

:

Gemini 2.0 Flash

Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, built-in tool use, multimodal generation, and a 1M token context window.

Context 1M

Input Tokens $0.15/M

Output Tokens $0.60/M

vertex logo
Available on 1 provider

moonshotai logo
Moonshot AI

:

Kimi K2

State of the art language model for agentic and coding tasks

Context 131K

Input Tokens $0.55/M

Output Tokens $2.20/M

baseten logo
deepinfra logo
fireworks logo
+4
Available on 7 providers

zai logo
Z.ai

:

GLM 4.5

GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.

Context 128K

Input Tokens $0.60/M

Output Tokens $2.20/M

novita logo
zai logo
Available on 2 providers

openai logo
OpenAI

:

GPT-4.1

GPT 4.1 is OpenAI's flagship model for complex tasks. It is well suited for problem solving across domains.

Context 1M

Input Tokens $2.00/M

Output Tokens $8.00/M

Cache Read Tokens $0.50/M

azure logo
openai logo
Available on 2 providers

anthropic logo
Anthropic

:

Claude 4.1 Opus

Claude Opus 4.1 is a drop-in replacement for Opus 4 that delivers superior performance and precision for real-world coding and agentic tasks. Opus 4.1 advances state-of-the-art coding performance to 74.5% on SWE-bench Verified, and handles complex, multi-step problems with more rigor and attention to detail.

Context 200K

Input Tokens $15.00/M

Output Tokens $75.00/M

Cache Read Tokens $1.50/M

Cache Write Tokens $18.75/M

anthropic logo
Available on 1 provider

openai logo
OpenAI

:

GPT-4o mini

GPT-4o mini from OpenAI is their most advanced and cost-efficient small model. It is multi-modal (accepting text or image inputs and outputting text) and has higher intelligence than gpt-3.5-turbo but is just as fast.

Context 128K

Input Tokens $0.15/M

Output Tokens $0.60/M

Cache Read Tokens $0.07/M

azure logo
openai logo
Available on 2 providers

google logo
Google

:

Gemini 2.5 Pro

Gemini 2.5 Pro is our most advanced reasoning Gemini model, capable of solving complex problems. It features a 2M token context window and supports multimodal inputs including text, images, audio, video, and PDF documents.

Context 1M

Input Tokens $2.50/M

Output Tokens $10.00/M

vertex logo
Available on 1 provider

openai logo
OpenAI

:

GPT-4.1 mini

GPT 4.1 mini provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases.

Context 1M

Input Tokens $0.40/M

Output Tokens $1.60/M

Cache Read Tokens $0.10/M

azure logo
openai logo
Available on 2 providers

anthropic logo
Anthropic

:

Claude 4 Opus

Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hours—dramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.

Context 200K

Input Tokens $15.00/M

Output Tokens $75.00/M

Cache Read Tokens $1.50/M

Cache Write Tokens $18.75/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

openai logo
OpenAI

:

GPT-4o

GPT-4o from OpenAI has broad general knowledge and domain expertise allowing it to follow complex instructions in natural language and solve difficult problems accurately. It matches GPT-4 Turbo performance with a faster and cheaper API.

Context 128K

Input Tokens $2.50/M

Output Tokens $10.00/M

Cache Read Tokens $1.25/M

azure logo
openai logo
Available on 2 providers

anthropic logo
Anthropic

:

Claude 3.5 Sonnet

Claude 3.5 Sonnet strikes the ideal balance between intelligence and speed—particularly for enterprise workloads. It delivers strong performance at a lower cost compared to its peers, and is engineered for high endurance in large-scale AI deployments.

Context 200K

Input Tokens $3.00/M

Output Tokens $15.00/M

Cache Read Tokens $0.30/M

Cache Write Tokens $3.75/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

xai logo
xAI

:

Grok 4

xAI's latest and greatest flagship model, offering unparalleled performance in natural language, math and reasoning - the perfect jack of all trades.

Context 256K

Input Tokens $3.00/M

Output Tokens $15.00/M

xai logo
Available on 1 provider

google logo
Google

:

Gemini 2.0 Flash Lite

Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, built-in tool use, multimodal generation, and a 1M token context window.

Context 1M

Input Tokens $0.07/M

Output Tokens $0.30/M

vertex logo
Available on 1 provider

alibaba logo
Alibaba Cloud

:

Qwen3 Coder

Qwen3 Coder 480B is a specialized programming model designed for ultra-efficient agentic code generation with long context and state-of-the-art performance. It excels at writing, debugging, and explaining code across multiple programming languages.

Context 131K

Input Tokens $0.40/M

Output Tokens $1.60/M

baseten logo
cerebras logo
deepinfra logo
+2
Available on 5 providers

deepseek logo
DeepSeek

:

DeepSeek R1

DeepSeek Reasoner is a specialized model developed by DeepSeek that uses Chain of Thought (CoT) reasoning to improve response accuracy. Before providing a final answer, it generates detailed reasoning steps that are accessible through the API, allowing users to examine and leverage the model's thought process, served by Fireworks AI.

Context 160K

Input Tokens $0.55/M

Output Tokens $2.19/M

baseten logo
bedrock logo
deepseek logo
+2
Available on 5 providers

alibaba logo
Alibaba Cloud

:

Qwen3 235B A22B Instruct 2507

Mixture-of-experts LLM with math and reasoning capabilities

Context 262K

Input Tokens $0.20/M

Output Tokens $0.60/M

baseten logo
deepinfra logo
fireworks logo
+1
Available on 4 providers

openai logo
OpenAI

:

o3

OpenAI's o3 is their most powerful reasoning model, setting new state-of-the-art benchmarks in coding, math, science, and visual perception. It excels at complex queries requiring multi-faceted analysis, with particular strength in analyzing images, charts, and graphics.

Context 200K

Input Tokens $2.00/M

Output Tokens $8.00/M

Cache Read Tokens $0.50/M

openai logo
Available on 1 provider

perplexity logo
Perplexity

:

Sonar

Perplexity's lightweight offering with search grounding, quicker and cheaper than Sonar Pro.

Context 127K

Input Tokens $1.00/M

Output Tokens $1.00/M

perplexity logo
Available on 1 provider

openai logo
OpenAI

:

text-embedding-3-small

OpenAI's improved, more performant version of their ada embedding model.

Input Tokens $0.02/M

azure logo
openai logo
Available on 2 providers

xai logo
xAI

:

Grok 3 Beta

xAI's flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.

Context 131K

Input Tokens $3.00/M

Output Tokens $15.00/M

xai logo
Available on 1 provider

xai logo
xAI

:

Grok 2 Vision

Grok 2 vision model excels in vision-based tasks, delivering state-of-the-art performance in visual math reasoning (MathVista) and document-based question answering (DocVQA). It can process a wide variety of visual information including documents, diagrams, charts, screenshots, and photographs.

Context 33K

Input Tokens $2.00/M

Output Tokens $10.00/M

xai logo
Available on 1 provider

anthropic logo
Anthropic

:

Claude 3.5 Haiku

Claude 3.5 Haiku is the next generation of our fastest model. For a similar speed to Claude 3 Haiku, Claude 3.5 Haiku improves across every skill set and surpasses Claude 3 Opus, the largest model in our previous generation, on many intelligence benchmarks.

Context 200K

Input Tokens $0.80/M

Output Tokens $4.00/M

Cache Read Tokens $0.08/M

Cache Write Tokens $1.00/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

openai logo
OpenAI

:

gpt-oss-20b

A compact, open-weight language model optimized for low-latency and resource-constrained environments, including local and edge deployments

Context 128K

Input Tokens $0.07/M

Output Tokens $0.30/M

fireworks logo
groq logo
Available on 2 providers

openai logo
OpenAI

:

o4-mini

OpenAI's o4-mini delivers fast, cost-efficient reasoning with exceptional performance for its size, particularly excelling in math (best-performing on AIME benchmarks), coding, and visual tasks.

Context 200K

Input Tokens $1.10/M

Output Tokens $4.40/M

Cache Read Tokens $0.28/M

azure logo
openai logo
Available on 2 providers

openai logo
OpenAI

:

GPT-4.1 nano

GPT-4.1 nano is the fastest, most cost-effective GPT 4.1 model.

Context 1M

Input Tokens $0.10/M

Output Tokens $0.40/M

Cache Read Tokens $0.03/M

azure logo
openai logo
Available on 2 providers

xai logo
xAI

:

Grok 3 Mini Beta

xAI's lightweight model that thinks before responding. Great for simple or logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.

Context 131K

Input Tokens $0.30/M

Output Tokens $0.50/M

xai logo
Available on 1 provider

zai logo
Z.ai

:

GLM 4.5 Air

GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.

Context 128K

Input Tokens $0.20/M

Output Tokens $1.10/M

zai logo
Available on 1 provider

openai logo
OpenAI

:

o3-mini

o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini.

Context 200K

Input Tokens $1.10/M

Output Tokens $4.40/M

Cache Read Tokens $0.55/M

azure logo
openai logo
Available on 2 providers

vercel logo
Vercel

:

v0-1.5-md

Access the model behind v0 to generate, fix, and optimize modern web apps with framework-specific reasoning and up-to-date knowledge.

Context 128K

Input Tokens $3.00/M

Output Tokens $15.00/M

vercel logo
Available on 1 provider

openai logo
OpenAI

:

GPT-4 Turbo

gpt-4-turbo from OpenAI has broad general knowledge and domain expertise allowing it to follow complex instructions in natural language and solve difficult problems accurately. It has a knowledge cutoff of April 2023 and a 128,000 token context window.

Context 128K

Input Tokens $10.00/M

Output Tokens $30.00/M

openai logo
Available on 1 provider

alibaba logo
Alibaba Cloud

:

Qwen 3.32B

Qwen3-32B is a world-class model with comparable quality to DeepSeek R1 while outperforming GPT-4.1 and Claude Sonnet 3.7. It excels in code-gen, tool-calling, and advanced reasoning, making it an exceptional model for a wide range of production use cases.

Context 128K

Input Tokens $0.10/M

Output Tokens $0.30/M

cerebras logo
deepinfra logo
groq logo
+1
Available on 4 providers

openai logo
OpenAI

:

GPT-3.5 Turbo

OpenAI's most capable and cost effective model in the GPT-3.5 family optimized for chat purposes, but also works well for traditional completions tasks.

Context 16K

Input Tokens $0.50/M

Output Tokens $1.50/M

openai logo
Available on 1 provider

xai logo
xAI

:

Grok 2

Grok 2 is a frontier language model with state-of-the-art reasoning capabilities. It features advanced capabilities in chat, coding, and reasoning, outperforming both Claude 3.5 Sonnet and GPT-4-Turbo on the LMSYS leaderboard.

Context 131K

Input Tokens $2.00/M

Output Tokens $10.00/M

xai logo
Available on 1 provider

perplexity logo
Perplexity

:

Sonar Pro

Perplexity's premier offering with search grounding, supporting advanced queries and follow-ups.

Context 200K

Input Tokens $3.00/M

Output Tokens $15.00/M

perplexity logo
Available on 1 provider

perplexity logo
Perplexity

:

Sonar Reasoning Pro

A premium reasoning-focused model that outputs Chain of Thought (CoT) in responses, providing comprehensive explanations with enhanced search capabilities and multiple search queries per request.

Context 127K

Input Tokens $2.00/M

Output Tokens $8.00/M

perplexity logo
Available on 1 provider

amazon logo
Amazon Bedrock

:

Nova Pro

A highly capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks.

Context 300K

Input Tokens $0.80/M

Output Tokens $3.20/M

bedrock logo
Available on 1 provider

cohere logo
Cohere

:

Command A

Command A is Cohere's most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.

Context 256K

Input Tokens $2.50/M

Output Tokens $10.00/M

cohere logo
Available on 1 provider

deepseek logo
DeepSeek

:

DeepSeek R1 Distill Llama 70B

DeepSeek-R1 is a state-of-the-art reasoning model trained with reinforcement learning and cold-start data, delivering strong performance across math, code, and complex reasoning tasks. It offers improved stability, readability, and multilingual handling compared to earlier versions, and is available alongside several high-quality distilled variants.

Context 128K

Input Tokens $0.75/M

Output Tokens $0.99/M

cerebras logo
groq logo
Available on 2 providers

perplexity logo
Perplexity

:

Sonar Reasoning

A reasoning-focused model that outputs Chain of Thought (CoT) in responses, providing detailed explanations with search grounding.

Context 127K

Input Tokens $1.00/M

Output Tokens $5.00/M

perplexity logo
Available on 1 provider

deepseek logo
DeepSeek

:

DeepSeek V3 0324

Fast general-purpose LLM with enhanced reasoning capabilities

Context 164K

Input Tokens $0.77/M

Output Tokens $0.77/M

baseten logo
fireworks logo
novita logo
+1
Available on 4 providers

meta logo
Meta

:

Llama 3.3 70B

The upgraded Llama 3.1 70B model features enhanced reasoning, tool use, and multilingual abilities, along with a significantly expanded 128K context window. These improvements make it well-suited for demanding tasks such as long-form summarization, multilingual conversations, and coding assistance.

Context 128K

Input Tokens $0.72/M

Output Tokens $0.72/M

bedrock logo
cerebras logo
groq logo
Available on 3 providers

vercel logo
Vercel

:

v0-1.0-md

Access the model behind v0 to generate, fix, and optimize modern web apps with framework-specific reasoning and up-to-date knowledge.

Context 128K

Input Tokens $3.00/M

Output Tokens $15.00/M

vercel logo
Available on 1 provider

mistral logo
Mistral

:

Mistral Large

Mistral Large is ideal for complex tasks that require large reasoning capabilities or are highly specialized - like Synthetic Text Generation, Code Generation, RAG, or Agents.

Context 32K

Input Tokens $2.00/M

Output Tokens $6.00/M

mistral logo
Available on 1 provider

meta logo
Meta

:

Llama 4 Maverick 17B 128E Instruct

High-efficiency language processing

Context 1M

Input Tokens $0.20/M

Output Tokens $0.60/M

baseten logo
bedrock logo
deepinfra logo
+1
Available on 4 providers

cohere logo
Cohere

:

Command R

Command R is a large language model optimized for conversational interaction and long context tasks. It targets the "scalable" category of models that balance high performance with strong accuracy, enabling companies to move beyond proof of concept and into production.

Context 128K

Input Tokens $0.15/M

Output Tokens $0.60/M

cohere logo
Available on 1 provider

google logo
Google

:

Gemini Embedding 001

State-of-the-art embedding model with excellent performance across English, multilingual and code tasks.

Input Tokens $0.15/M

google logo
vertex logo
Available on 2 providers

anthropic logo
Anthropic

:

Claude 3 Haiku

Claude 3 Haiku is Anthropic's fastest model yet, designed for enterprise workloads which often involve longer prompts. Haiku to quickly analyze large volumes of documents, such as quarterly filings, contracts, or legal cases, for half the cost of other models in its performance tier.

Context 200K

Input Tokens $0.25/M

Output Tokens $1.25/M

Cache Read Tokens $0.03/M

Cache Write Tokens $0.30/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

cohere logo
Cohere

:

Embed v4.0

A model that allows for text, images, or mixed content to be classified or turned into embeddings.

Input Tokens $0.12/M

cohere logo
Available on 1 provider

meta logo
Meta

:

Llama 3.1 8B

Llama 3.1 8B brings powerful performance in a smaller, more efficient package. With improved multilingual support, tool use, and a 128K context length, it enables sophisticated use cases like interactive agents and compact coding assistants while remaining lightweight and accessible.

Context 128K

Input Tokens $0.05/M

Output Tokens $0.08/M

bedrock logo
cerebras logo
groq logo
Available on 3 providers

meta logo
Meta

:

Llama 3.2 1B Instruct

Text-only model, supporting on-device use cases such as multilingual local knowledge retrieval, summarization, and rewriting.

Context 128K

Input Tokens $0.10/M

Output Tokens $0.10/M

bedrock logo
Available on 1 provider

amazon logo
Amazon Bedrock

:

Nova Micro

A text-only model that delivers the lowest latency responses at very low cost.

Context 128K

Input Tokens $0.04/M

Output Tokens $0.14/M

bedrock logo
Available on 1 provider

alibaba logo
Alibaba Cloud

:

Qwen3-14B

Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support

Context 41K

Input Tokens $0.08/M

Output Tokens $0.24/M

deepinfra logo
Available on 1 provider

anthropic logo
Anthropic

:

Claude 3 Opus

Claude 3 Opus is Anthropic's most intelligent model, with best-in-market performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Opus shows us the outer limits of what's possible with generative AI.

Context 200K

Input Tokens $15.00/M

Output Tokens $75.00/M

Cache Read Tokens $1.50/M

Cache Write Tokens $18.75/M

anthropic logo
bedrock logo
vertexAnthropic logo
Available on 3 providers

openai logo
OpenAI

:

o1

o1 is OpenAI's flagship reasoning model, designed for complex problems that require deep thinking. It provides strong reasoning capabilities with improved accuracy for complex multi-step tasks.

Context 200K

Input Tokens $15.00/M

Output Tokens $60.00/M

Cache Read Tokens $7.50/M

azure logo
openai logo
Available on 2 providers

xai logo
xAI

:

Grok 3 Mini Fast Beta

xAI's lightweight model that thinks before responding. Great for simple or logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible. The fast model variant is served on faster infrastructure, offering response times that are significantly faster than the standard. The increased speed comes at a higher cost per output token.

Context 131K

Input Tokens $0.60/M

Output Tokens $4.00/M

xai logo
Available on 1 provider

meta logo
Meta

:

Llama 3 70B Instruct

Llama is a 70 billion parameter open source model by Meta fine-tuned for instruction following purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.

Context 8K

Input Tokens $0.59/M

Output Tokens $0.79/M

groq logo
Available on 1 provider

openai logo
OpenAI

:

text-embedding-ada-002

OpenAI's legacy text embedding model.

Input Tokens $0.10/M

azure logo
openai logo
Available on 2 providers

alibaba logo
Alibaba Cloud

:

Qwen3-30B-A3B

Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support

Context 41K

Input Tokens $0.10/M

Output Tokens $0.30/M

deepinfra logo
Available on 1 provider

amazon logo
Amazon Bedrock

:

Nova Lite

A very low cost multimodal model that is lightning fast for processing image, video, and text inputs.

Context 300K

Input Tokens $0.06/M

Output Tokens $0.24/M

bedrock logo
Available on 1 provider

amazon logo
Amazon Bedrock

:

Titan Text Embeddings V2

Amazon Titan Text Embeddings V2 is a light weight, efficient multilingual embedding model supporting 1024, 512, and 256 dimensions.

Input Tokens $0.02/M

bedrock logo
Available on 1 provider

cohere logo
Cohere

:

Command R+

Command R+ is Cohere's newest large language model, optimized for conversational interaction and long-context tasks. It aims at being extremely performant, enabling companies to move beyond proof of concept and into production.

Context 128K

Input Tokens $2.50/M

Output Tokens $10.00/M

cohere logo
Available on 1 provider

google logo
Google

:

Gemma 2 9B IT

9 billion parameter open source model by Google fine-tuned for chat purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.

Context 8K

Input Tokens $0.20/M

Output Tokens $0.20/M

groq logo
Available on 1 provider

google logo
Google

:

Text Embedding 005

English-focused text embedding model optimized for code and English language tasks.

Input Tokens $0.03/M

vertex logo
Available on 1 provider

google logo
Google

:

Text Multilingual Embedding 002

Multilingual text embedding model optimized for cross-lingual tasks across many languages.

Input Tokens $0.03/M

vertex logo
Available on 1 provider

inception logo
Inception

:

Mercury Coder Small Beta

Mercury Coder Small is ideal for code generation, debugging, and refactoring tasks with minimal latency.

Context 32K

Input Tokens $0.25/M

Output Tokens $1.00/M

inception logo
Available on 1 provider

meta logo
Meta

:

Llama 3 8B Instruct

Llama is a 8 billion parameter open source model by Meta fine-tuned for instruction following purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.

Context 8K

Input Tokens $0.05/M

Output Tokens $0.08/M

groq logo
Available on 1 provider

meta logo
Meta

:

Llama 3.1 70B Instruct

An update to Meta Llama 3 70B Instruct that includes an expanded 128K context length, multilinguality and improved reasoning capabilities.

Context 128K

Input Tokens $0.72/M

Output Tokens $0.72/M

bedrock logo
Available on 1 provider

meta logo
Meta

:

Llama 3.2 11B Vision Instruct

Instruction-tuned image reasoning generative model (text + images in / text out) optimized for visual recognition, image reasoning, captioning and answering general questions about the image.

Context 128K

Input Tokens $0.16/M

Output Tokens $0.16/M

bedrock logo
Available on 1 provider

meta logo
Meta

:

Llama 3.2 3B Instruct

Text-only model, fine-tuned for supporting on-device use cases such as multilingual local knowledge retrieval, summarization, and rewriting.

Context 128K

Input Tokens $0.15/M

Output Tokens $0.15/M

bedrock logo
Available on 1 provider

meta logo
Meta

:

Llama 3.2 90B Vision Instruct

Instruction-tuned image reasoning generative model (text + images in / text out) optimized for visual recognition, image reasoning, captioning and answering general questions about the image.

Context 128K

Input Tokens $0.72/M

Output Tokens $0.72/M

bedrock logo
Available on 1 provider

meta logo
Meta

:

Llama 4 Scout

The Llama-4-Scout-17B-16E-Instruct model is a state-of-the-art, instruction-tuned, multimodal AI model developed by Meta as part of the Llama 4 family. It is designed to handle both text and image inputs, making it suitable for a wide range of applications, including conversational AI, code generation, and visual reasoning.

Context 128K

Input Tokens $0.10/M

Output Tokens $0.30/M

baseten logo
bedrock logo
cerebras logo
+3
Available on 6 providers

mistral logo
Mistral

:

Codestral Embed

Code embedding model that can embed code databases and repositories to power coding assistants.

Input Tokens $0.15/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Devstral Small

Devstral is an agentic LLM for software engineering tasks, making it a great choice for software engineering agents.

Context 128K

Input Tokens $0.07/M

Output Tokens $0.28/M

deepinfra logo
mistral logo
Available on 2 providers

mistral logo
Mistral

:

Magistral Medium 2506

Complex thinking, backed by deep understanding, with transparent reasoning you can follow and verify. The model excels in maintaining high-fidelity reasoning across numerous languages, even when switching between languages mid-task.

Context 128K

Input Tokens $2.00/M

Output Tokens $5.00/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Magistral Small 2506

Complex thinking, backed by deep understanding, with transparent reasoning you can follow and verify. The model excels in maintaining high-fidelity reasoning across numerous languages, even when switching between languages mid-task.

Context 128K

Input Tokens $0.50/M

Output Tokens $1.50/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Ministral 3B

A compact, efficient model for on-device tasks like smart assistants and local analytics, offering low-latency performance.

Context 128K

Input Tokens $0.04/M

Output Tokens $0.04/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Ministral 8B

A more powerful model with faster, memory-efficient inference, ideal for complex workflows and demanding edge applications.

Context 128K

Input Tokens $0.10/M

Output Tokens $0.10/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Mistral Codestral 25.01

Mistral Codestral 25.01 is a state-of-the-art coding model optimized for low-latency, high-frequency use cases. Proficient in over 80 programming languages, it excels at tasks like fill-in-the-middle (FIM), code correction, and test generation.

Context 256K

Input Tokens $0.30/M

Output Tokens $0.90/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Mistral Embed

General-purpose text embedding model for semantic search, similarity, clustering, and RAG workflows.

Input Tokens $0.10/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Mistral Saba 24B

Mistral Saba 24B is a 24 billion parameter open source model by Mistral.ai. Saba is a specialized model trained to excel in Arabic, Farsi, Urdu, Hebrew, and Indic languages. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.

Context 33K

Input Tokens $0.79/M

Output Tokens $0.79/M

groq logo
Available on 1 provider

mistral logo
Mistral

:

Mistral Small

Mistral Small is the ideal choice for simple tasks that one can do in bulk - like Classification, Customer Support, or Text Generation. It offers excellent performance at an affordable price point.

Context 32K

Input Tokens $0.10/M

Output Tokens $0.30/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Mixtral MoE 8x22B Instruct

8x22b Instruct model. 8x22b is mixture-of-experts open source model by Mistral served by Fireworks.

Context 66K

Input Tokens $1.20/M

Output Tokens $1.20/M

fireworks logo
Available on 1 provider

mistral logo
Mistral

:

Pixtral 12B 2409

A 12B model with image understanding capabilities in addition to text.

Context 128K

Input Tokens $0.15/M

Output Tokens $0.15/M

mistral logo
Available on 1 provider

mistral logo
Mistral

:

Pixtral Large

Pixtral Large is the second model in our multimodal family and demonstrates frontier-level image understanding. Particularly, the model is able to understand documents, charts and natural images, while maintaining the leading text-only understanding of Mistral Large 2.

Context 128K

Input Tokens $2.00/M

Output Tokens $6.00/M

mistral logo
Available on 1 provider

morph logo
Morph

:

Morph V3 Fast

Morph offers a specialized AI model that applies code changes suggested by frontier models (like Claude or GPT-4o) to your existing code files FAST - 4500+ tokens/second. It acts as the final step in the AI coding workflow. Supports 16k input tokens and 16k output tokens.

Context 33K

Input Tokens $0.80/M

Output Tokens $1.20/M

morph logo
Available on 1 provider

morph logo
Morph

:

Morph V3 Large

Morph offers a specialized AI model that applies code changes suggested by frontier models (like Claude or GPT-4o) to your existing code files FAST - 2500+ tokens/second. It acts as the final step in the AI coding workflow. Supports 16k input tokens and 16k output tokens.

Context 33K

Input Tokens $0.90/M

Output Tokens $1.90/M

morph logo
Available on 1 provider

openai logo
OpenAI

:

GPT-3.5 Turbo Instruct

Similar capabilities as GPT-3 era models. Compatible with legacy Completions endpoint and not Chat Completions.

Context 8K

Input Tokens $1.50/M

Output Tokens $2.00/M

openai logo
Available on 1 provider

openai logo
OpenAI

:

text-embedding-3-large

OpenAI's most capable embedding model for both english and non-english tasks.

Input Tokens $0.13/M

azure logo
openai logo
Available on 2 providers

xai logo
xAI

:

Grok 3 Fast Beta

xAI's flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science. The fast model variant is served on faster infrastructure, offering response times that are significantly faster than the standard. The increased speed comes at a higher cost per output token.

Context 131K

Input Tokens $5.00/M

Output Tokens $25.00/M

xai logo
Available on 1 provider